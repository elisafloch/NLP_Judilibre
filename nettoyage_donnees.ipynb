{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des donnees\n",
    "df = pd.read_csv('data_nlp.csv')\n",
    "\n",
    "# Remplacer les caract√®res de nouvelle ligne par des espaces vides\n",
    "df['text'] = df['text'].replace('\\n', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb Cellule 3\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f62333331653531632d336434342d343562342d613666322d3263363432656362323432632f7265736f7572636547726f7570732f6d616e2d617a2d77652d617a6d6c2d706f632f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d616e2d617a2d77652d617a6d6c2d706f632d616d6c732f636f6d70757465732f73616e626f782d696e7374616e63652d45464c/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m text \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39misalnum()]\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f62333331653531632d336434342d343562342d613666322d3263363432656362323432632f7265736f7572636547726f7570732f6d616e2d617a2d77652d617a6d6c2d706f632f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d616e2d617a2d77652d617a6d6c2d706f632d616d6c732f636f6d70757465732f73616e626f782d696e7374616e63652d45464c/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m### LEMMATISATION\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f62333331653531632d336434342d343562342d613666322d3263363432656362323432632f7265736f7572636547726f7570732f6d616e2d617a2d77652d617a6d6c2d706f632f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d616e2d617a2d77652d617a6d6c2d706f632d616d6c732f636f6d70757465732f73616e626f782d696e7374616e63652d45464c/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mfr_core_news_md\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f62333331653531632d336434342d343562342d613666322d3263363432656362323432632f7265736f7572636547726f7570732f6d616e2d617a2d77652d617a6d6c2d706f632f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d616e2d617a2d77652d617a6d6c2d706f632d616d6c732f636f6d70757465732f73616e626f782d696e7374616e63652d45464c/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatisation\u001b[39m(text):\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f62333331653531632d336434342d343562342d613666322d3263363432656362323432632f7265736f7572636547726f7570732f6d616e2d617a2d77652d617a6d6c2d706f632f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d616e2d617a2d77652d617a6d6c2d706f632d616d6c732f636f6d70757465732f73616e626f782d696e7374616e63652d45464c/home/azureuser/cloudfiles/code/Users/e.floch/nlp_judilibre/NLP_Judilibre/nettoyage_donnees.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     lem \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     37\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     38\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig\n\u001b[1;32m     53\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/util.py:420\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[1;32m    419\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/util.py:453\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/fr_core_news_md/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moverrides)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/util.py:619\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    618\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[0;32m--> 619\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[1;32m    620\u001b[0m     data_path,\n\u001b[1;32m    621\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    622\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    623\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    624\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    625\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    626\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/util.py:488\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    486\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config)\n\u001b[1;32m    487\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m--> 488\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    489\u001b[0m     config, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, meta\u001b[39m=\u001b[39;49mmeta\n\u001b[1;32m    490\u001b[0m )\n\u001b[1;32m    491\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/util.py:528\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[1;32m    527\u001b[0m lang_cls \u001b[39m=\u001b[39m get_lang_class(nlp_config[\u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 528\u001b[0m nlp \u001b[39m=\u001b[39m lang_cls\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[1;32m    529\u001b[0m     config,\n\u001b[1;32m    530\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    531\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    532\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    533\u001b[0m     auto_fill\u001b[39m=\u001b[39;49mauto_fill,\n\u001b[1;32m    534\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    535\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    537\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/language.py:1809\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     factory \u001b[39m=\u001b[39m pipe_cfg\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfactory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1807\u001b[0m     \u001b[39m# The pipe name (key in the config) here is the unique name\u001b[39;00m\n\u001b[1;32m   1808\u001b[0m     \u001b[39m# of the component, not necessarily the factory\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     nlp\u001b[39m.\u001b[39;49madd_pipe(\n\u001b[1;32m   1810\u001b[0m         factory,\n\u001b[1;32m   1811\u001b[0m         name\u001b[39m=\u001b[39;49mpipe_name,\n\u001b[1;32m   1812\u001b[0m         config\u001b[39m=\u001b[39;49mpipe_cfg,\n\u001b[1;32m   1813\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   1814\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m   1815\u001b[0m     )\n\u001b[1;32m   1816\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[39m# We need the sourced components to reference the same\u001b[39;00m\n\u001b[1;32m   1818\u001b[0m     \u001b[39m# vocab without modifying the current vocab state **AND**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[39m# during deserialization, so they do not need any\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m     \u001b[39m# additional handling.\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m     \u001b[39mif\u001b[39;00m vocab_b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/language.py:795\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    788\u001b[0m         err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    789\u001b[0m             name\u001b[39m=\u001b[39mfactory_name,\n\u001b[1;32m    790\u001b[0m             opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m             lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[1;32m    794\u001b[0m         )\n\u001b[0;32m--> 795\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[1;32m    796\u001b[0m         factory_name,\n\u001b[1;32m    797\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    798\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    799\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[1;32m    800\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    801\u001b[0m     )\n\u001b[1;32m    802\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    803\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/language.py:674\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    671\u001b[0m cfg \u001b[39m=\u001b[39m {factory_name: config}\n\u001b[1;32m    672\u001b[0m \u001b[39m# We're calling the internal _fill here to avoid constructing the\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[39m# registered functions twice\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m resolved \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39;49mresolve(cfg, validate\u001b[39m=\u001b[39;49mvalidate)\n\u001b[1;32m    675\u001b[0m filled \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39mfill({\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m: cfg[factory_name]}, validate\u001b[39m=\u001b[39mvalidate)[\u001b[39m\"\u001b[39m\u001b[39mcfg\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    676\u001b[0m filled \u001b[39m=\u001b[39m Config(filled)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/config.py:746\u001b[0m, in \u001b[0;36mregistry.resolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    738\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve\u001b[39m(\n\u001b[1;32m    739\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     validate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 746\u001b[0m     resolved, _ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_make(\n\u001b[1;32m    747\u001b[0m         config, schema\u001b[39m=\u001b[39;49mschema, overrides\u001b[39m=\u001b[39;49moverrides, validate\u001b[39m=\u001b[39;49mvalidate, resolve\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m     \u001b[39mreturn\u001b[39;00m resolved\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/config.py:795\u001b[0m, in \u001b[0;36mregistry._make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interpolated:\n\u001b[1;32m    794\u001b[0m     config \u001b[39m=\u001b[39m Config(orig_config)\u001b[39m.\u001b[39minterpolate()\n\u001b[0;32m--> 795\u001b[0m filled, _, resolved \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[1;32m    796\u001b[0m     config, schema, validate\u001b[39m=\u001b[39;49mvalidate, overrides\u001b[39m=\u001b[39;49moverrides, resolve\u001b[39m=\u001b[39;49mresolve\n\u001b[1;32m    797\u001b[0m )\n\u001b[1;32m    798\u001b[0m filled \u001b[39m=\u001b[39m Config(filled, section_order\u001b[39m=\u001b[39msection_order)\n\u001b[1;32m    799\u001b[0m \u001b[39m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/config.py:850\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    848\u001b[0m     schema\u001b[39m.\u001b[39m__fields__[key] \u001b[39m=\u001b[39m copy_model_field(field, Any)\n\u001b[1;32m    849\u001b[0m promise_schema \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmake_promise_schema(value, resolve\u001b[39m=\u001b[39mresolve)\n\u001b[0;32m--> 850\u001b[0m filled[key], validation[v_key], final[key] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_fill(\n\u001b[1;32m    851\u001b[0m     value,\n\u001b[1;32m    852\u001b[0m     promise_schema,\n\u001b[1;32m    853\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    854\u001b[0m     resolve\u001b[39m=\u001b[39;49mresolve,\n\u001b[1;32m    855\u001b[0m     parent\u001b[39m=\u001b[39;49mkey_parent,\n\u001b[1;32m    856\u001b[0m     overrides\u001b[39m=\u001b[39;49moverrides,\n\u001b[1;32m    857\u001b[0m )\n\u001b[1;32m    858\u001b[0m reg_name, func_name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_constructor(final[key])\n\u001b[1;32m    859\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mparse_args(final[key])\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/config.py:867\u001b[0m, in \u001b[0;36mregistry._fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    864\u001b[0m     getter \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget(reg_name, func_name)\n\u001b[1;32m    865\u001b[0m     \u001b[39m# We don't want to try/except this and raise our own error\u001b[39;00m\n\u001b[1;32m    866\u001b[0m     \u001b[39m# here, because we want the traceback if the function fails.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     getter_result \u001b[39m=\u001b[39m getter(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[39m# We're not resolving and calling the function, so replace\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# the getter_result with a Promise class\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     getter_result \u001b[39m=\u001b[39m Promise(\n\u001b[1;32m    872\u001b[0m         registry\u001b[39m=\u001b[39mreg_name, name\u001b[39m=\u001b[39mfunc_name, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    873\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/spacy/ml/models/parser.py:87\u001b[0m, in \u001b[0;36mbuild_tb_parser_model\u001b[0;34m(tok2vec, state_type, extra_state_tokens, hidden_width, maxout_pieces, use_upper, nO)\u001b[0m\n\u001b[1;32m     85\u001b[0m upper \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m use_upper:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mwith\u001b[39;00m use_ops(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     88\u001b[0m         \u001b[39m# Initialize weights at zero, as it's a classification layer.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         upper \u001b[39m=\u001b[39m _define_upper(nO\u001b[39m=\u001b[39mnO, nI\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m TransitionModel(tok2vec, lower, upper, resize_output)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/backends/__init__.py:122\u001b[0m, in \u001b[0;36muse_ops\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m\"\"\"Change the backend to execute on for the scope of the block.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m current_ops \u001b[39m=\u001b[39m get_current_ops()\n\u001b[0;32m--> 122\u001b[0m set_current_ops(get_ops(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    123\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/backends/__init__.py:140\u001b[0m, in \u001b[0;36mset_current_ops\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m    138\u001b[0m context_ops\u001b[39m.\u001b[39mset(ops)\n\u001b[1;32m    139\u001b[0m _get_thread_state()\u001b[39m.\u001b[39mops \u001b[39m=\u001b[39m ops\n\u001b[0;32m--> 140\u001b[0m set_torch_tensor_type_for_ops(ops)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/thinc/util.py:529\u001b[0m, in \u001b[0;36mset_torch_tensor_type_for_ops\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcupy_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m CupyOps\n\u001b[1;32m    528\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     \u001b[39mif\u001b[39;00m CupyOps\u001b[39m.\u001b[39mxp \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(ops, CupyOps):\n\u001b[1;32m    532\u001b[0m         torch\u001b[39m.\u001b[39mset_default_tensor_type(\u001b[39m\"\u001b[39m\u001b[39mtorch.cuda.FloatTensor\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/pd39/lib/python3.9/site-packages/torch/__init__.py:457\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    455\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[1;32m    458\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    459\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "### NETTOYAGE REGEX\n",
    "def nettoyage_regex(text):\n",
    "    text = re.sub(r'\\d+', '', text)  # Enl√®ve les chiffres\n",
    "    \n",
    "    return text\n",
    "\n",
    "### TOKENISATION\n",
    "def tokenisation(text):\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    tweet_tokens = [tokenizer.tokenize(text)]\n",
    "    return tweet_tokens[0]\n",
    "\n",
    "### STOP WORDS\n",
    "stop_words = stopwords.words('french')\n",
    "new_stopwords = [\"avoir\", \"√™tre\", \"article\", \"loi\", \"cour\", \"appel\", \"article\", \"code\",\n",
    "                \"chambre\", \"civile\", \"cassation\", \"proc√©dure\", \"x\", \"y\", \"z\", \"mme\", \"mlle\",\n",
    "                \"janvier\", \"f√©vrier\", \"mars\", \"avril\", \"mai\", \"juin\", \"juillet\", \"ao√ªt\",\n",
    "                \"septembre\", \"octobre\", \"novembre\", \"d√©cembre\", \"lundi\", \"mardi\",\n",
    "                \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\", \"dimanche\",\"a\", \"e\", \"b\",\n",
    "                \"deuxi√®me\", \"rendu\" ,\"arr√™t\" ,\"suivant\" ,\"moyen\" ,\"unique\", \"selon\",\n",
    "                \"demande\" ,\"avis\", \"s√©ance\" ,\"juridiction\", \"tribunal\" ,\"grande\" ,\"instance\",\n",
    "                \"nom\" ,\"peuple\" ,\"francais\" ,\"deuxieme\" , \"premier\",\"premiere\", \"premi√®re\", \"troisi√®me\" ,\n",
    "                \"pourvoi\", \"pris\",\n",
    "                \"form√©\", \"criminelle\", \"audience\", \"publique\", \"paris\", \"tenue\", \"palais\", \"justice\",\n",
    "                \"dont\", \"si√®ge\"]\n",
    "stop_words.extend(new_stopwords)\n",
    "stop_words = set(stop_words)\n",
    "def stop_words_function(text):\n",
    "    return [w.lower() for w in text if not w.lower() in stop_words]\n",
    "\n",
    "## SUPPRESSION PONCTUATION\n",
    "def suppr_ponct(text):\n",
    "    return [token for token in text if token.isalnum()]\n",
    "\n",
    "### LEMMATISATION\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "def lemmatisation(text):\n",
    "    lem = []\n",
    "    for i in range(len(text)):\n",
    "        doc = nlp(text[i])\n",
    "        for token in doc:\n",
    "            lem.append(token.lemma_)\n",
    "    return lem\n",
    "\n",
    "def nettoyage(text):\n",
    "    text = nettoyage_regex(text)\n",
    "    text = tokenisation(text)\n",
    "    text = suppr_ponct(text)\n",
    "    #text = lemmatisation(text)\n",
    "    text = stop_words_function(text)\n",
    "    return text\n",
    "\n",
    "def nettoyage_phrase(text):\n",
    "    text = nettoyage_regex(text)\n",
    "    text = tokenisation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the cleaned text\n",
    "cleaned_text = []\n",
    "# loop through all the rows in the 'text' column\n",
    "for text in df['text']:\n",
    "    # apply the 'nettoyage' function to clean the text\n",
    "    cleaned = nettoyage(text)\n",
    "    # add the cleaned text to the list\n",
    "    cleaned_text.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [' '.join(words) for words in cleaned_text]\n",
    "cleaned_text_df = pd.DataFrame().assign(text=cleaned_text)\n",
    "\n",
    "cleaned_text_df.to_csv(\"cleaned_text2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the cleaned text\n",
    "cleaned_phrase = []\n",
    "# loop through all the rows in the 'text' column\n",
    "for text in df['text']:\n",
    "    # apply the 'nettoyage' function to clean the text\n",
    "    cleaned = nettoyage_phrase(text)\n",
    "    # add the cleaned text to the list\n",
    "    cleaned_phrase.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases\n",
    "cleaned_phrase = [' '.join(words) for words in cleaned_phrase]\n",
    "cleaned_phrase_df = pd.DataFrame().assign(text=cleaned_phrase)\n",
    "\n",
    "cleaned_phrase_df.to_csv(\"cleaned_phrase2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 for Problem Detection",
   "language": "python",
   "name": "pd39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0194299e911b6a22f0cd3d1c9a66c991d39f48b249be23f24104e40900e329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
