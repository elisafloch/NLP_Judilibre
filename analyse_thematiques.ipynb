{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation library\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation données\n",
    "deci_jur = pd.read_csv(\"cleaned_text2.csv\",  encoding = \"utf-8\")\n",
    "\n",
    "# Suppresion des valeurs manquantes\n",
    "deci_jur = deci_jur.dropna()\n",
    "deci_jur = deci_jur.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la liste des tweets\n",
    "list_deci_jur = []\n",
    "for i in range(len(deci_jur)):\n",
    "   list_deci_jur.append(str(deci_jur.iloc[i, 1]).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant réaliser une analyse thématique. Pour choisir le nombre de groupes, nous sommes parties avec 10 groupes. Les groupes se ressemblaient trop. Nous avons donc diminué le nombre de groupe jusqu'à arriver à 3 groupes. Les groupes sont assez caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group :  (0, '0.018*\"vehicule\" + 0.016*\"accident\" + 0.013*\"attendu\" + 0.008*\"societe\" + 0.008*\"alors\" + 0.007*\"fait\" + 0.007*\"victime\" + 0.007*\"cause\"')\n",
      "Group :  (1, '0.013*\"attendu\" + 0.013*\"avocat\" + 0.012*\"faute\" + 0.010*\"conseiller\" + 0.008*\"ou\" + 0.008*\"fait\" + 0.008*\"demeurant\" + 0.008*\"general\"')\n",
      "Group :  (2, '0.013*\"victime\" + 0.012*\"prejudice\" + 0.009*\"attendu\" + 0.008*\"assureur\" + 0.007*\"accident\" + 0.006*\"indemnite\" + 0.006*\"assurances\" + 0.006*\"droit\"')\n"
     ]
    }
   ],
   "source": [
    "# Pré-traitement des données\n",
    "dictionary = corpora.Dictionary(list_deci_jur)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in list_deci_jur]\n",
    "\n",
    "# Entraînement du modèle LDA\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=3, random_state=100,\n",
    "                     update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
    "\n",
    "# Afficher les thèmes générés par le modèle LDA\n",
    "topics = lda_model.print_topics(num_words=8)\n",
    "for topic in topics:\n",
    "    print(\"Group : \", topic)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc 3 groupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 for Problem Detection",
   "language": "python",
   "name": "pd39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
